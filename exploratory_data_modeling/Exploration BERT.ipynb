{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config file\n",
    "with open('../config/config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "file_path = config[\"data_loc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inference batch has 1097 observations and 4 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34902587</td>\n",
       "      <td>Detection of porcine circovirus type 3 DNA in ...</td>\n",
       "      <td>Porcine circovirus type 3 (PCV3) is regularly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35451025</td>\n",
       "      <td>Imputation of non-genotyped F1 dams to improve...</td>\n",
       "      <td>This study investigated using imputed genotype...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34859764</td>\n",
       "      <td>Proposed multidimensional pain outcome methodo...</td>\n",
       "      <td>Castration of male piglets in the United State...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35143972</td>\n",
       "      <td>Nanostructured lipid carriers loaded with an a...</td>\n",
       "      <td>Alopecia is a condition associated with differ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34872491</td>\n",
       "      <td>Genome-wide expression of the residual lung re...</td>\n",
       "      <td>BACKGROUND: Acute or chronic irreversible resp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                              Title  \\\n",
       "0  34902587  Detection of porcine circovirus type 3 DNA in ...   \n",
       "1  35451025  Imputation of non-genotyped F1 dams to improve...   \n",
       "2  34859764  Proposed multidimensional pain outcome methodo...   \n",
       "3  35143972  Nanostructured lipid carriers loaded with an a...   \n",
       "4  34872491  Genome-wide expression of the residual lung re...   \n",
       "\n",
       "                                            Abstract  Label  \n",
       "0  Porcine circovirus type 3 (PCV3) is regularly ...      0  \n",
       "1  This study investigated using imputed genotype...      0  \n",
       "2  Castration of male piglets in the United State...      0  \n",
       "3  Alopecia is a condition associated with differ...      0  \n",
       "4  BACKGROUND: Acute or chronic irreversible resp...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define file path\n",
    "file_name = \"test_unlabeled.tsv\"\n",
    "final_path = os.path.join(file_path, file_name) \n",
    "\n",
    "# Load tsv file\n",
    "inference_batch = pd.read_csv(final_path, sep='\\t')\n",
    "print(f\"The inference batch has {inference_batch.shape[0]} observations and {inference_batch.shape[1]} columns.\")\n",
    "inference_batch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the original dataset: (11278, 4) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17179536</td>\n",
       "      <td>Variance component analysis of quantitative tr...</td>\n",
       "      <td>In a previous study, QTL for carcass compositi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17177700</td>\n",
       "      <td>Single nucleotide polymorphism identification,...</td>\n",
       "      <td>Pituitary adenylate cyclase-activating polypep...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17129674</td>\n",
       "      <td>Genetic resistance to Sarcocystis miescheriana...</td>\n",
       "      <td>Clinical and parasitological traits of Sarcocy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17121599</td>\n",
       "      <td>Results of a whole-genome quantitative trait l...</td>\n",
       "      <td>A whole-genome quantitative trait locus (QTL) ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17057239</td>\n",
       "      <td>Unexpected high polymorphism at the FABP4 gene...</td>\n",
       "      <td>Fatty acid bing protein 4 (FABP4) plays a key ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                              Title  \\\n",
       "0  17179536  Variance component analysis of quantitative tr...   \n",
       "1  17177700  Single nucleotide polymorphism identification,...   \n",
       "2  17129674  Genetic resistance to Sarcocystis miescheriana...   \n",
       "3  17121599  Results of a whole-genome quantitative trait l...   \n",
       "4  17057239  Unexpected high polymorphism at the FABP4 gene...   \n",
       "\n",
       "                                            Abstract  Category  \n",
       "0  In a previous study, QTL for carcass compositi...         1  \n",
       "1  Pituitary adenylate cyclase-activating polypep...         0  \n",
       "2  Clinical and parasitological traits of Sarcocy...         0  \n",
       "3  A whole-genome quantitative trait locus (QTL) ...         1  \n",
       "4  Fatty acid bing protein 4 (FABP4) plays a key ...         0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define file path\n",
    "file_name = \"QTL_text.json\"\n",
    "final_path = os.path.join(file_path, file_name) \n",
    "\n",
    "# Load json file\n",
    "df = pd.read_json(final_path)\n",
    "df = df.drop(columns=['Journal'])\n",
    "print(f\"Shape of the original dataset: {df.shape}\", \"\\n\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictor and target features\n",
    "X = df.drop(columns=['Category'])\n",
    "y = df['Category']\n",
    "\n",
    "# Split train and test\n",
    "X_train_corpus, X_test, y_train_corpus, y_test = train_test_split(X,y, test_size=.2, random_state=42, stratify=y)\n",
    "\n",
    "# Split train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_corpus,y_train_corpus, test_size=.2, random_state=42, stratify=y_train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define pre-trained model path\n",
    "model_path = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "# Load model tokeninzer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load model with binary classification head\n",
    "id2label = {0: \"Not Related\", 1: \"Related\"}\n",
    "label2id = {\"Not Related\": 0, \"Related\": 1}\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path,\n",
    "                                                           num_labels=2,\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Trainable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all base model parameters\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "# Unfreeze base model pooling layers\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"pooler\" in name:\n",
    "        param.requires_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 7217\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 1805\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 2256\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data\n",
    "train_data = {\"text\": X_train['Title'], \"labels\": y_train}\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "\n",
    "# Validation Data\n",
    "val_data = {\"text\": X_val['Title'], \"labels\": y_val}\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "\n",
    "# Test Data\n",
    "test_data = {\"text\": X_test['Title'], \"labels\": y_test}\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1612e48be39d4f069f10a0785605623b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7217 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee2a987fa674db49b7b4b6635d11c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1805 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da82330469474c44989d608adab992a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define text preprocessing\n",
    "def preprocess_function(examples):\n",
    "    # Return tokenized text with truncation\n",
    "    return tokenizer(\n",
    "        examples['text'], \n",
    "        truncation=True) # Truncate abstracts greater than 512 tokens\n",
    "\n",
    "# Preprocess all datasets\n",
    "tokenized_data = dataset_dict.map(preprocess_function, batched=True)\n",
    "\n",
    "# Create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # Uniform sample lenght"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Evaluation Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "f1_score = evaluate.load(\"f1\", config=\"macro\")\n",
    "auc_score = evaluate.load(\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    # Get predictions\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = np.exp(predictions)  / np.exp(predictions).sum(-1, keepdims=True)\n",
    "\n",
    "    # Use probabilities of the positive class for ROC AUC\n",
    "    positive_class_probs = probabilities[:, 1]\n",
    "\n",
    "    # Compute AUC\n",
    "    auc = np.round(auc_score.compute(prediction_scores=positive_class_probs, references=labels)['roc_auc'], 3)\n",
    "\n",
    "\n",
    "    # Predict most probable class\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Compute Accuracy\n",
    "    f1 = np.round(f1_score.compute(predictions=predicted_classes, references=labels)['f1'], 4)\n",
    "\n",
    "    return {\"F1\": f1, \"AUC\": auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 2e-4\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"experiment_outputs\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/7bp3qrzx7dx95tf0806th2rw0000gn/T/ipykernel_31230/656748127.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data['train'],\n",
    "    eval_dataset=tokenized_data['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9030' max='9030' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9030/9030 33:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.161634</td>\n",
       "      <td>0.634900</td>\n",
       "      <td>0.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.173800</td>\n",
       "      <td>0.161501</td>\n",
       "      <td>0.593800</td>\n",
       "      <td>0.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.159940</td>\n",
       "      <td>0.606700</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.174800</td>\n",
       "      <td>0.152787</td>\n",
       "      <td>0.652600</td>\n",
       "      <td>0.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.168700</td>\n",
       "      <td>0.152580</td>\n",
       "      <td>0.653800</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9030, training_loss=0.08670167975779519, metrics={'train_runtime': 1992.2586, 'train_samples_per_second': 36.225, 'train_steps_per_second': 4.533, 'total_flos': 1517765886730980.0, 'train_loss': 0.08670167975779519, 'epoch': 10.0})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.train()\n",
    "# To resume from the last checkpoint in your output_dir:\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='92' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 92/282 00:27 < 00:58, 3.26 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply model to validation dataset\n",
    "predictions = trainer.predict(tokenized_data[\"test\"])\n",
    "\n",
    "# Extract the logits and labels from the predictions object\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Compute metrics\n",
    "metrics = compute_metrics((logits, labels))\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
